{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Exercise 5.2 (a)\n",
    "\n",
    "def single_mode_matricization(T, j):\n",
    "    \"\"\"\n",
    "    Matricization of numpy array `T` by partitioning into j-th dimension and the remaining dimensions.\n",
    "    \"\"\"\n",
    "    assert j < T.ndim\n",
    "    # bring j-th dimension to the front\n",
    "    T = np.transpose(T, [j] + list(range(j)) + list(range(j + 1, T.ndim)))\n",
    "    T = np.reshape(T, (T.shape[0], -1)) # size of second dimension is inferred\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Exercise 5.2 (b)\n",
    "\n",
    "def single_mode_product(A, T, j):\n",
    "    \"\"\"\n",
    "    Compute the j-mode product between the matrix `A` and tensor `T`.\n",
    "    \"\"\"\n",
    "    T = np.tensordot(A, T, axes=(1, j))\n",
    "    # original j-th dimension is now 0-th dimension; move back to j-th place\n",
    "    T = np.transpose(T, list(range(1, j + 1)) + [0] + list(range(j + 1, T.ndim)))\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuckerTensor(object):\n",
    "    \"\"\"\n",
    "    Tucker format tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, Ulist, C):\n",
    "        self.Ulist = [np.array(U) for U in Ulist]\n",
    "        # core tensor\n",
    "        self.C = np.array(C)\n",
    "        # dimension consistency checks\n",
    "        assert len(self.Ulist) == self.C.ndim\n",
    "        for j in range(self.C.ndim):\n",
    "            assert self.Ulist[j].shape[1] == C.shape[j]\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        \"\"\"Logical dimensions.\"\"\"\n",
    "        return tuple([U.shape[0] for U in self.Ulist])\n",
    "\n",
    "    @property\n",
    "    def ndim(self):\n",
    "        \"\"\"Number of logical dimensions.\"\"\"\n",
    "        return len(self.Ulist)\n",
    "\n",
    "    def as_full_tensor(self):\n",
    "        \"\"\"\n",
    "        Construct the Tucker format tensor as full (dense) array.\n",
    "\n",
    "        Note: Should only be used for debugging and testing.\n",
    "        \"\"\"\n",
    "        T = self.C\n",
    "        for j in range(T.ndim):\n",
    "            # apply Uj to j-th dimension\n",
    "            T = single_mode_product(self.Ulist[j], T, j)\n",
    "        return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Exercise 5.2 (d)\n",
    "\n",
    "def higher_order_svd(T, max_ranks):\n",
    "    \"\"\"\n",
    "    Compute the higher-order singular value decomposition\n",
    "    (Tucker format approximation) of the NumPy array `T`.\n",
    "    \"\"\"\n",
    "    assert T.ndim == len(max_ranks)\n",
    "    Ulist = []\n",
    "    σlist = []\n",
    "    for j in range(T.ndim):\n",
    "        A = single_mode_matricization(T, j)\n",
    "        U, σ, Vh = np.linalg.svd(A, full_matrices=False)\n",
    "        χ = U.shape[1]\n",
    "        if max_ranks[j] > 0:\n",
    "            # truncate in case max_ranks[j] < χ\n",
    "            χ = min(χ, max_ranks[j])\n",
    "        Ulist.append(U[:, :χ])\n",
    "        σlist.append(σ)\n",
    "    # form the core tensor\n",
    "    C = T\n",
    "    for j in range(C.ndim):\n",
    "        # apply Uj^\\dagger to j-th dimension\n",
    "        C = single_mode_product(Ulist[j].conj().T, C, j)\n",
    "    return TuckerTensor(Ulist, C), σlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_second_derivative_zero_boundary(n):\n",
    "    \"\"\"\n",
    "    Finite difference discretization of -d^2/dx^2 on [0, 1] with zero boundary conditions.\n",
    "    \"\"\"\n",
    "    # TODO: implement this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 21\n",
    "\n",
    "A = fd_second_derivative_zero_boundary(n)\n",
    "\n",
    "# visualize eigenvalues\n",
    "plt.plot(np.linalg.eigvalsh(A), '.')\n",
    "plt.xlabel(\"j\")\n",
    "plt.ylabel(r\"$\\lambda_j$\")\n",
    "plt.title(\"eigenvalues of FD approximation of -d^2/dx^2\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A is symmetric and all eigenvalues are larger than zero, i.e., A is positive definite\n",
    "min(np.linalg.eigvalsh(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as short test, this should be zero:\n",
    "abs(min(np.linalg.eigvalsh(A)) - 9.851211269436485)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `L` operator as full matrix, as reference and for tests\n",
    "L = (\n",
    "    np.kron(np.kron(A,                   np.identity(len(A))), np.identity(len(A))) +\n",
    "    np.kron(np.kron(np.identity(len(A)), A                  ), np.identity(len(A))) +\n",
    "    np.kron(np.kron(np.identity(len(A)), np.identity(len(A))), A                  ))\n",
    "print(L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_form_tucker_isometry(A, phi: TuckerTensor, j):\n",
    "    \"\"\"\n",
    "    Construct the square matrix `K` which expresses <phi, L phi> with\n",
    "    L = A x I x ... x I + ... + I x ... x I x A\n",
    "    in dependence of the j-th isometry `phi.Ulist[j]`, such that\n",
    "    <phi, L phi> = <u_j, K u_j> with u_j = phi.Ulist[j].flatten().\n",
    "    \"\"\"\n",
    "    # TODO: implement this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test of `quadratic_form_tucker_isometry`\n",
    "kdim_test = (2, 3, 4)\n",
    "ϕtest = TuckerTensor([np.linalg.qr(np.random.randn(n-1, kdim_test[j]))[0] for j in range(3)], np.random.standard_normal(kdim_test))\n",
    "ϕtvec = np.reshape(ϕtest.as_full_tensor(), -1)\n",
    "utest = [np.reshape(ϕtest.Ulist[j], -1) for j in range(3)]\n",
    "# reference value\n",
    "ϕLϕref = np.dot(ϕtvec, L @ ϕtvec)\n",
    "# relative error should be zero up to numerical rounding errors\n",
    "err = [abs(np.dot(utest[j], quadratic_form_tucker_isometry(A, ϕtest, j) @ utest[j]) - ϕLϕref) / abs(ϕLϕref) for j in range(3)]\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_form_tucker_isometry(phi: TuckerTensor, b: TuckerTensor, j):\n",
    "    \"\"\"\n",
    "    Construct the vector `g` which expresses <phi, b>\n",
    "    in dependence of the j-th isometry `phi.Ulist[j]`, such that\n",
    "    <phi, b> = <u_j, g> with u_j = phi.Ulist[j].flatten().\n",
    "    \"\"\"\n",
    "    # all but j-th dimension\n",
    "    jcompl = list(range(j)) + list(range(j + 1, phi.ndim))\n",
    "    g = phi.C\n",
    "    for k in jcompl:\n",
    "        g = single_mode_product(b.Ulist[k].T @ phi.Ulist[k], g, k)\n",
    "    g = b.Ulist[j] @ np.tensordot(b.C, g, axes=(jcompl, jcompl))\n",
    "    assert g.shape == phi.Ulist[j].shape\n",
    "    return np.reshape(g, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_form_tucker_core(A, phi: TuckerTensor):\n",
    "    \"\"\"\n",
    "    Construct the square matrix `K` which expresses <phi, L phi> with\n",
    "    L = A x I x ... x I + ... + I x ... x I x A\n",
    "    in dependence of the core tensor `phi.C`, such that\n",
    "    <phi, L phi> = <c, K c> with c = phi.C.flatten().\n",
    "    \"\"\"\n",
    "    K = np.zeros((phi.C.size, phi.C.size))\n",
    "    for j in range(phi.ndim):\n",
    "        K1 = np.identity(1)\n",
    "        for k in range(phi.ndim):\n",
    "            K1 = np.kron(K1, phi.Ulist[k].T @ A @ phi.Ulist[k] if k == j else np.identity(phi.Ulist[k].shape[1]))\n",
    "        K += K1\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_form_tucker_core(phi: TuckerTensor, b: TuckerTensor):\n",
    "    \"\"\"\n",
    "    Construct the vector `g` which expresses <phi, b>\n",
    "    in dependence of the core tensor `phi.C`, such that\n",
    "    <phi, b> = <c, g> with c = phi.C.flatten().\n",
    "    \"\"\"\n",
    "    # construct temporary Tucker format tensor\n",
    "    Alist = [phi.Ulist[j].T @ b.Ulist[j] for j in range(phi.ndim)]\n",
    "    g = TuckerTensor(Alist, b.C).as_full_tensor()\n",
    "    return np.reshape(g, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorized_tucker_als_step(A, phi: TuckerTensor, b: TuckerTensor):\n",
    "    \"\"\"\n",
    "    Alternating Least Squares (ALS) optimization step of a Tucker format tensor `phi`\n",
    "    for target function 1/2 <phi, L phi> - <phi, b> with\n",
    "    L = A x I x ... x I + ... I x ... x I x A.\n",
    "    \"\"\"\n",
    "    assert phi.ndim == b.ndim\n",
    "    # optimize U matrices one-by-one\n",
    "    for j in range(phi.ndim):\n",
    "        # construct least squares terms for Ulist[j]\n",
    "        K = quadratic_form_tucker_isometry(A, phi, j)\n",
    "        g = linear_form_tucker_isometry(phi, b, j)\n",
    "        Ujnext = np.reshape(np.linalg.solve(K, g), phi.Ulist[j].shape)\n",
    "        # perform QR decomposition to ensure Ulist[j] remains an isometry\n",
    "        phi.Ulist[j], R = np.linalg.qr(Ujnext, mode='reduced')\n",
    "        # absorb R into core tensor\n",
    "        phi.C = single_mode_product(R, phi.C, j)\n",
    "    # optimize core tensor\n",
    "    K = quadratic_form_tucker_core(A, phi)\n",
    "    g = linear_form_tucker_core(phi, b)\n",
    "    phi.C = np.reshape(np.linalg.solve(K, g), phi.C.shape)\n",
    "    # result is stored in updated `phi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct `b` tensor\n",
    "\n",
    "bfull = np.array([[[np.sin(3*np.pi*(i + j + k)/n) for k in range(1, n)] for j in range(1, n)] for i in range(1, n)])\n",
    "print(\"bfull.shape:\", bfull.shape)\n",
    "\n",
    "# keep only 2 singular values along each dimension\n",
    "b, σlistb = higher_order_svd(bfull, [2, 2, 2])\n",
    "\n",
    "print(\"b Tucker approximation error:\", np.linalg.norm(np.reshape(b.as_full_tensor() - bfull, -1)) / np.linalg.norm(np.reshape(bfull, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some singular values from HOSVD of `b`\n",
    "plt.semilogy(range(1, len(σlistb[0]) + 1), σlistb[0]**2 / np.sum(σlistb[0]**2), '.')\n",
    "plt.axvline(x=2.5)\n",
    "plt.ylabel(\"$\\\\sigma_j^2$\")\n",
    "plt.xlabel(\"$j$\")\n",
    "plt.title(\"normalized singular values for `b` along dimension 0\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference solution\n",
    "print(\"Solving reference linear system...\")\n",
    "ϕref = np.reshape(np.linalg.solve(L, np.reshape(bfull, -1)), bfull.shape)\n",
    "print(\"done.\")\n",
    "print(\"ϕref.shape:\", ϕref.shape)\n",
    "plt.imshow(ϕref[:, :, n//2], extent=[0,1,0,1])\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"reference ϕ(x, y, z) at z = 0.5\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run optimization\n",
    "\n",
    "# initial tensor\n",
    "np.random.seed(42)\n",
    "k = 4\n",
    "ϕ = TuckerTensor([np.linalg.qr(np.random.randn(n-1, k), mode='reduced')[0] for _ in range(3)], np.random.randn(k, k, k))\n",
    "\n",
    "numiter = 6\n",
    "errlist = []\n",
    "for i in range(numiter):\n",
    "    factorized_tucker_als_step(A, ϕ, b)\n",
    "    errlist.append(np.linalg.norm(ϕ.as_full_tensor() - ϕref) / np.linalg.norm(ϕref))\n",
    "\n",
    "plt.semilogy(range(1, numiter + 1), errlist)\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"relative error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core tensor\n",
    "ϕ.C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize Tucker format approximation (should be visually indistinguishable from reference solution)\n",
    "ϕfull = ϕ.as_full_tensor()\n",
    "plt.imshow(ϕfull[:, :, n//2], extent=[0,1,0,1])\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Tucker ϕ(x, y, z) at z = 0.5\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
